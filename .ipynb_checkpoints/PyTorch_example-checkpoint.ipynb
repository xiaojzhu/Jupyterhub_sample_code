{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import seaborn as sns\n",
    "import copy\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "'''\n",
    "Super hacky plot making below\n",
    "'''\n",
    "\n",
    "# plt.ion()\n",
    "# plt.figure(figsize=(10,7))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N=1000, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    features = []\n",
    "    target = []\n",
    "\n",
    "    for i in range(N):\n",
    "        r = np.random.uniform()\n",
    "        theta = np.random.uniform(0, 2*np.pi)\n",
    "\n",
    "        features.append([r*np.cos(theta), r*np.sin(theta)])\n",
    "        target.append(0)\n",
    "\n",
    "        r = 3 + np.random.uniform()\n",
    "        theta = np.random.uniform(0, 2*np.pi)\n",
    "\n",
    "        features.append([r*np.cos(theta), r*np.sin(theta)])\n",
    "        target.append(1)\n",
    "\n",
    "    features = np.array(features)\n",
    "    target = np.array(target)\n",
    "\n",
    "    return features, target\n",
    "\n",
    "def simple_model(features, target, plot_decision=False):\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    model.fit(features, target)\n",
    "\n",
    "    pred = model.predict(features)\n",
    "\n",
    "    accuracy = np.sum(pred==target)/float(len(target))\n",
    "    print(f'Accuracy = {accuracy}')\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(features[target==0][:,0], features[target==0][:,1], 'p', color='r', label='0')\n",
    "    plt.plot(features[target==1][:,0], features[target==1][:,1], 'p', color='g', label='1')\n",
    "\n",
    "    #u*x + v*y + w = 0\n",
    "    # y = -w/v - u*x/v\n",
    "    if plot_decision:\n",
    "        x_vals, y_vals = [], []\n",
    "        for x in [-4, 4]: #silly but don't worry\n",
    "            y = (-1./model.coef_[0][1]) * (model.intercept_ + model.coef_[0][0] * x)\n",
    "\n",
    "            x_vals.append(x)\n",
    "            y_vals.append(y)\n",
    "\n",
    "        plt.plot(x_vals, y_vals, label='decision boundary')\n",
    "    plt.xlim(features[:,0].min(), features[:,0].max())\n",
    "    plt.ylim(features[:,1].min(), features[:,1].max())\n",
    "\n",
    "    if plot_decision:\n",
    "        falsepred = np.where(pred!=target)[0]\n",
    "        plt.plot(features[falsepred][:,0], features[falsepred][:,1], 'p', color='y', label='incorrect')\n",
    "        plt.title(f'Logistic Regression - accuracy = {accuracy}')\n",
    "\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend(framealpha=0)\n",
    "\n",
    "    return model\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, N_input=2, N_output=1, N_hidden_layers=1, N_hidden_nodes=10):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(N_input, N_hidden_nodes)\n",
    "        self.hidden = nn.ModuleList([])\n",
    "        for i in range(N_hidden_layers-1):\n",
    "            self.hidden.append(nn.Linear(N_hidden_nodes, N_hidden_nodes))\n",
    "        self.linear2 = nn.Linear(N_hidden_nodes, N_output)  \n",
    "\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.output_activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.activation(self.linear1(x))\n",
    "        for layer in self.hidden:\n",
    "            out = self.activation(layer(out))\n",
    "        out = self.output_activation(self.linear2(out))\n",
    "\n",
    "        return out\n",
    "\n",
    "def train_model(features, target, model, lr, N_epochs, shuffle=False):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model = model.to(device)\n",
    "    features = features.to(device)\n",
    "    target = target.to(device)\n",
    "\n",
    "    for epoch in range(N_epochs):\n",
    "        if shuffle: #should have no effect on gradients\n",
    "            indices = torch.randperm(len(features))\n",
    "\n",
    "            features_shuffled = features[indices]\n",
    "            target_shuffled = target[indices]\n",
    "        else:\n",
    "            features_shuffled = features\n",
    "            target_shuffled = target\n",
    "\n",
    "        out = model(features_shuffled)\n",
    "        loss = criterion(out, target_shuffled)\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f'epoch = {epoch} loss = {loss}')\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    pred = model(features_shuffled).reshape(len(target))\n",
    "    pred[pred>0.5] = 1\n",
    "    pred[pred<=0.5] = 0\n",
    "\n",
    "    accuracy = torch.sum(pred==target.reshape(len(target)))\n",
    "    print(f'Accuracy = {accuracy}')\n",
    "\n",
    "    model = model.to('cpu')\n",
    "    features = features.to('cpu')\n",
    "    target = target.to('cpu')\n",
    "\n",
    "    return model\n",
    "\n",
    "def introspect(features, target, model):\n",
    "    '''Only if exactly 1 hidden layer -> draw decision boundaries and mark incorrect predictions\n",
    "    '''\n",
    "    params = list(model.parameters()) #small model\n",
    "    \n",
    "    weights = params[0].detach().numpy()\n",
    "    biases = params[1].detach().numpy()\n",
    "\n",
    "    #plot raw data\n",
    "    features = copy.copy(features).detach().numpy()\n",
    "    target = copy.copy(target).detach().numpy()\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(features[target==0][:,0], features[target==0][:,1], 'p', color='r', label='0')\n",
    "    plt.plot(features[target==1][:,0], features[target==1][:,1], 'p', color='g', label='1')\n",
    "\n",
    "    x_min, x_max = features[:,0].min(), features[:,0].max()\n",
    "    y_lim_min, y_lim_max = features[:,1].min(), features[:,1].max()\n",
    "    for i in range(weights.shape[0]): #plot each decision boundary\n",
    "        coef = weights[i]\n",
    "        intercept = biases[i]\n",
    "\n",
    "        #coef[0] * x + coef[1] * y + intercept = 0 -> decision boundary for sigmoid\n",
    "        #y = (-intercept - coef[0]*x) / coef[1]\n",
    "        y_min = (-intercept - coef[0]*x_min)/coef[1]\n",
    "        y_max = (-intercept - coef[0]*x_max)/coef[1]\n",
    "\n",
    "        plt.plot([x_min, x_max], [y_min, y_max])\n",
    "\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_lim_min, y_lim_max)\n",
    "\n",
    "    '''Plot inaccurate pred at threshold=0.5'''\n",
    "    pred = model(torch.Tensor(features)).reshape(len(target)).detach().numpy()\n",
    "    pred[pred<=0.5] = 0\n",
    "    pred[pred>0.5] = 1\n",
    "\n",
    "    labels = target.reshape(len(target))\n",
    "    falsepred = np.where(pred!=labels)[0]\n",
    "\n",
    "    plt.plot(features[falsepred][:,0], features[falsepred][:,1], 'p', color='y', label='incorrect')\n",
    "\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend(framealpha=0)\n",
    "    plt.title(f'Decision boundaries for each node ({model.linear1.out_features}) in hidden layer')\n",
    "\n",
    "\n",
    "\n",
    "def introspect_2hidden(features, target, model, plot_out_db=False):\n",
    "    '''Hacky but okay\n",
    "    Plots for input, db, second layer activations and second layer db\n",
    "    '''\n",
    "    params = list(model.parameters()) #small model\n",
    "    \n",
    "    features = copy.copy(features).detach().numpy()\n",
    "    target = copy.copy(target).reshape(len(target)).detach().numpy()\n",
    "\n",
    "    #plot original data\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(121)\n",
    "\n",
    "    ax1.plot(features[target==0][:,0], features[target==0][:,1], 'p', color='r', label='0')\n",
    "    ax1.plot(features[target==1][:,0], features[target==1][:,1], 'p', color='g', label='1')\n",
    "\n",
    "    #plot original data - decision boundaries\n",
    "    weights = params[0].detach().numpy()\n",
    "    biases = params[1].detach().numpy()\n",
    "\n",
    "    x_min, x_max = features[:,0].min(), features[:,0].max()\n",
    "    y_lim_min, y_lim_max = features[:,1].min(), features[:,1].max()\n",
    "    for i in range(weights.shape[0]): #plot each decision boundary\n",
    "        coef = weights[i]\n",
    "        intercept = biases[i]\n",
    "\n",
    "        #coef[0] * x + coef[1] * y + intercept = 0 -> decision boundary for sigmoid\n",
    "        #y = (-intercept - coef[0]*x) / coef[1]\n",
    "        y_min = (-intercept - coef[0]*x_min)/coef[1]\n",
    "        y_max = (-intercept - coef[0]*x_max)/coef[1]\n",
    "\n",
    "        ax1.plot([x_min, x_max], [y_min, y_max])\n",
    "\n",
    "    ax1.set_xlim(x_min, x_max)\n",
    "    ax1.set_ylim(y_lim_min, y_lim_max)\n",
    "    ax1.legend(framealpha=0)\n",
    "\n",
    "    #plot transformation in layer 1\n",
    "    layer1_act = model.activation(model.linear1(torch.Tensor(features))).detach().numpy()\n",
    "\n",
    "    if model.linear1.out_features==3:\n",
    "        ax2 = fig.add_subplot(122, projection='3d')\n",
    "        ax2.plot(layer1_act[target==0][:,0], layer1_act[target==0][:,1], layer1_act[target==0][:,2], 'p', color='r', label='0')\n",
    "        ax2.plot(layer1_act[target==1][:,0], layer1_act[target==1][:,1], layer1_act[target==1][:,2], 'p', color='g', label='1')\n",
    "    else:\n",
    "        ax2 = fig.add_subplot(122)\n",
    "        ax2.plot(layer1_act[target==0][:,0], layer1_act[target==0][:,1], 'p', color='r', label='0')\n",
    "        ax2.plot(layer1_act[target==1][:,0], layer1_act[target==1][:,1], 'p', color='g', label='1')\n",
    "\n",
    "    ax2.legend(framealpha=0)\n",
    "\n",
    "    if plot_out_db:\n",
    "        '''Should really create a different function for this'''\n",
    "        coef = params[2].detach().numpy()[0]\n",
    "        intercept = params[3].detach().numpy()[0]\n",
    "\n",
    "        x_min, x_max = layer1_act[:,0].min(), layer1_act[:,0].max()\n",
    "        y_min, y_max = layer1_act[:,1].min(), layer1_act[:,1].max()\n",
    "        \n",
    "        if model.linear1.out_features==3:\n",
    "            z_lim_min, z_lim_max = layer1_act[:,2].min(), layer1_act[:,2].max()\n",
    "\n",
    "            #coef[0]*x + coef[1]*y + coef[2]*z + intercept = 0\n",
    "            #\n",
    "            '''\n",
    "            z_min = (-intercept - coef[0]*x_min - coef[1]*y_min)/coef[1]\n",
    "            z_max = (-intercept - coef[0]*x_max - coef[1]*y_max)/coef[1]\n",
    "            z_mixed = (-intercept - coef[0]*x_min - coef[1]*y_max)/coef[1]\n",
    "            ax2.plot_surface([x_min, x_max, x_min], [y_min, y_max, y_max], [z_min, z_max, z_mixed], color='black', label='decision boundary')\n",
    "            ax2.set_xlim(x_min, x_max)\n",
    "            ax2.set_ylim(y_min, y_max)\n",
    "            ax2.set_zlim(z_lim_min, z_lim_max)\n",
    "            ax2.legend(framealpha=0)\n",
    "            '''\n",
    "\n",
    "\n",
    "        else:\n",
    "            #coef[0] * x + coef[1] * y + intercept = 0 -> decision boundary for sigmoid\n",
    "            #y = (-intercept - coef[0]*x) / coef[1]\n",
    "            y_min = (-intercept - coef[0]*x_min)/coef[1]\n",
    "            y_max = (-intercept - coef[0]*x_max)/coef[1]\n",
    "\n",
    "            ax2.plot([x_min, x_max], [y_min, y_max], color='black', label='decision boundary')\n",
    "\n",
    "            ax2.set_xlim(x_min, x_max)\n",
    "            ax2.set_ylim(y_lim_min, y_lim_max)\n",
    "            ax2.legend(framealpha=0)\n",
    "\n",
    "def introspect_feature_transforms(features, target, model):\n",
    "    '''dim 2 -> dim 2 -> ... -> dim 2 -> output\n",
    "    '''\n",
    "    params = list(model.parameters()) #small model\n",
    "\n",
    "    #collect all activations starting from input data    \n",
    "    activations = [features.detach().numpy()]\n",
    "\n",
    "    out = model.activation(model.linear1(features))\n",
    "    activations.append(out.detach().numpy())\n",
    "\n",
    "    for layer in model.hidden:\n",
    "        out = model.activation(layer(out))\n",
    "        activations.append(out.detach().numpy())\n",
    "\n",
    "    #plotting\n",
    "    features = copy.copy(features).detach().numpy()\n",
    "    target = copy.copy(target).reshape(len(target)).detach().numpy()\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    counter = 1\n",
    "    for act in activations:\n",
    "        ax = fig.add_subplot(f'1{len(activations)}{counter}')\n",
    "\n",
    "        ax.plot(act[target==0][:,0], act[target==0][:,1], 'p', color='r', label='0')\n",
    "        ax.plot(act[target==1][:,0], act[target==1][:,1], 'p', color='g', label='1')\n",
    "\n",
    "        #plot decision boundaries (2)\n",
    "\n",
    "        counter += 1\n",
    "    return activations\n",
    "\n",
    "def run(N_hidden_nodes=5, N_epochs=1000):\n",
    "    x,y = generate_data(seed = 0)\n",
    "\n",
    "    x, y = torch.Tensor(x), torch.Tensor(y).reshape(len(y),1)\n",
    "\n",
    "    model = Net(N_input=2, N_output=1, N_hidden_layers=1, N_hidden_nodes=N_hidden_nodes)\n",
    "    model = train_model(x,y, model, 1e-3, N_epochs)\n",
    "    introspect(x,y.reshape(len(y)),model)\n",
    "\n",
    "    return x,y,model\n",
    "\n",
    "    Â© 2019 GitHub, Inc.\n",
    "    Terms\n",
    "    Privacy\n",
    "    Security\n",
    "    Status\n",
    "    Help\n",
    "\n",
    "    Contact GitHub\n",
    "    Pricing\n",
    "    API\n",
    "    Training\n",
    "    Blog\n",
    "    About\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
